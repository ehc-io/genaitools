{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0f1bea346db"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Install the latest version of Cloud Storage and the Vertex AI SDK for Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfbccc635a17"
      },
      "outputs": [],
      "source": [
        "# Install the packages\n",
        "! pip3 install --upgrade google-cloud-aiplatform==1.35.0 \\\n",
        "                         google-cloud-storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97473593f37f"
      },
      "source": [
        "Install the latest version of google-cloud-vision for filtering for safe images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5709d1d57927"
      },
      "outputs": [],
      "source": [
        "# Install the packages\n",
        "! pip install google-cloud-vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd28c9e4f067"
      },
      "source": [
        "#### Set your project ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "80c0215f05a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "PROJECT_ID = \"ai-1684952810\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}\n",
        "REGION = \"us-central1\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eab0cbaef92"
      },
      "source": [
        "#### Defining encoding functions\n",
        "\n",
        "Create an EmbeddingPredictionClient which encapsulates the logic to call the embedding API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ec925af6f502"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import time\n",
        "import typing\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "from google.protobuf import struct_pb2\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class EmbeddingResponse(typing.NamedTuple):\n",
        "    text_embedding: typing.Sequence[float]\n",
        "    image_embedding: typing.Sequence[float]\n",
        "\n",
        "\n",
        "def load_image_bytes(image_uri: str) -> bytes:\n",
        "    \"\"\"Load image bytes from a remote or local URI.\"\"\"\n",
        "    image_bytes = None\n",
        "    if image_uri.startswith(\"http://\") or image_uri.startswith(\"https://\"):\n",
        "        response = requests.get(image_uri, stream=True)\n",
        "        if response.status_code == 200:\n",
        "            image_bytes = response.content\n",
        "    else:\n",
        "        image_bytes = open(image_uri, \"rb\").read()\n",
        "    return image_bytes\n",
        "\n",
        "class EmbeddingPredictionClient:\n",
        "    \"\"\"Wrapper around Prediction Service Client.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        project: str,\n",
        "        location: str = \"us-central1\",\n",
        "        api_regional_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
        "    ):\n",
        "        client_options = {\"api_endpoint\": api_regional_endpoint}\n",
        "        # Initialize client that will be used to create and send requests.\n",
        "        # This client only needs to be created once, and can be reused for multiple requests.\n",
        "        self.client = aiplatform.gapic.PredictionServiceClient(\n",
        "            client_options=client_options\n",
        "        )\n",
        "        self.location = location\n",
        "        self.project = project\n",
        "\n",
        "    def get_mm_embedding(self, text: str = None, image_file: str = None):\n",
        "        if not text and not image_file:\n",
        "            raise ValueError(\"At least one of text or image_file must be specified.\")\n",
        "\n",
        "        # Load image file\n",
        "        image_bytes = None\n",
        "        if image_file:\n",
        "            image_bytes = load_image_bytes(image_file)\n",
        "\n",
        "        instance = struct_pb2.Struct()\n",
        "        if text:\n",
        "            instance.fields[\"text\"].string_value = text\n",
        "\n",
        "        if image_bytes:\n",
        "            encoded_content = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
        "            image_struct = instance.fields[\"image\"].struct_value\n",
        "            image_struct.fields[\"bytesBase64Encoded\"].string_value = encoded_content\n",
        "\n",
        "        instances = [instance]\n",
        "        endpoint = (\n",
        "            f\"projects/{self.project}/locations/{self.location}\"\n",
        "            \"/publishers/google/models/multimodalembedding@001\"\n",
        "        )\n",
        "        response = self.client.predict(endpoint=endpoint, instances=instances)\n",
        "\n",
        "        text_embedding = None\n",
        "        if text:\n",
        "            text_emb_value = response.predictions[0][\"textEmbedding\"]\n",
        "            text_embedding = [v for v in text_emb_value]\n",
        "\n",
        "        image_embedding = None\n",
        "        if image_bytes:\n",
        "            image_emb_value = response.predictions[0][\"imageEmbedding\"]\n",
        "            image_embedding = [v for v in image_emb_value]\n",
        "        \n",
        "        return EmbeddingResponse(\n",
        "            text_embedding=text_embedding, image_embedding=image_embedding\n",
        "        )\n",
        "        \n",
        "    def get_text_embedding(self, text: str):\n",
        "        instance = struct_pb2.Struct()\n",
        "        instance.fields[\"text\"].string_value = text\n",
        "\n",
        "        instances = [instance]\n",
        "        endpoint = (\n",
        "            f\"projects/{self.project}/locations/{self.location}\"\n",
        "            \"/publishers/google/models/multimodalembedding@001\"\n",
        "        )\n",
        "        response = self.client.predict(endpoint=endpoint, instances=instances)\n",
        "\n",
        "        text_emb_value = response.predictions[0][\"textEmbedding\"]\n",
        "        text_embedding = [v for v in text_emb_value]\n",
        "        return text_embedding\n",
        "\n",
        "    def get_image_embedding(self, image_file: str):\n",
        "        image_bytes = load_image_bytes(image_file)\n",
        "\n",
        "        instance = struct_pb2.Struct()\n",
        "        encoded_content = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
        "        image_struct = instance.fields[\"image\"].struct_value\n",
        "        image_struct.fields[\"bytesBase64Encoded\"].string_value = encoded_content\n",
        "\n",
        "        instances = [instance]\n",
        "        endpoint = (\n",
        "            f\"projects/{self.project}/locations/{self.location}\"\n",
        "            \"/publishers/google/models/multimodalembedding@001\"\n",
        "        )\n",
        "        response = self.client.predict(endpoint=endpoint, instances=instances)\n",
        "\n",
        "        image_emb_value = response.predictions[0][\"imageEmbedding\"]\n",
        "        image_embedding = [v for v in image_emb_value]\n",
        "        return image_embedding\n",
        "    \n",
        "def embedding_distance(\n",
        "    embedding1: np.ndarray, embedding2: np.ndarray\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Compute the distance between two embeddings using the dot product.\n",
        "\n",
        "    Args:\n",
        "        embedding1 (np.ndarray): The first embedding vector.\n",
        "        embedding2 (np.ndarray): The second embedding vector.\n",
        "\n",
        "    Returns:\n",
        "        float: The distance between the two embeddings.\n",
        "    \"\"\"\n",
        "    if embedding1 is None or embedding2 is None:\n",
        "        raise ValueError(\"Both embeddings must be provided.\")\n",
        "\n",
        "    if embedding1.shape != embedding2.shape:\n",
        "        raise ValueError(\"Embeddings must have the same shape.\")\n",
        "\n",
        "    return np.dot(embedding1, embedding2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f18ecd0b068"
      },
      "source": [
        "#### Test the encoding function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "##### Image vs Text Comparison "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "e = EmbeddingPredictionClient(PROJECT_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance: 0.0809066133683251\n"
          ]
        }
      ],
      "source": [
        "r = e.get_mm_embedding(\"Vinho Branco\", \"images/screenshot-20240422-23.20.19.png\")\n",
        "text_embedding = r.__getattribute__(\"text_embedding\")\n",
        "image_embeddings = r.__getattribute__(\"image_embedding\")\n",
        "distances = embedding_distance(np.array(text_embedding), np.array(image_embeddings))\n",
        "print(f\"Distance: {distances}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance: 0.15198525073474012\n"
          ]
        }
      ],
      "source": [
        "r = e.get_mm_embedding(\"Vinho Tinto\", \"images/screenshot-20240422-23.20.19.png\")\n",
        "text_embedding = r.__getattribute__(\"text_embedding\")\n",
        "image_embeddings = r.__getattribute__(\"image_embedding\")\n",
        "distances = embedding_distance(np.array(text_embedding), np.array(image_embeddings))\n",
        "print(f\"Distance: {distances}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance: 0.15198525073474012\n"
          ]
        }
      ],
      "source": [
        "r = e.get_mm_embedding(\"Vinho Tinto\", \"images/screenshot-20240422-23.20.19.png\")\n",
        "text_embedding = r.__getattribute__(\"text_embedding\")\n",
        "image_embeddings = r.__getattribute__(\"image_embedding\")\n",
        "distances = embedding_distance(np.array(text_embedding), np.array(image_embeddings))\n",
        "print(f\"Distance: {distances}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance: 0.15198525073474012\n"
          ]
        }
      ],
      "source": [
        "r = e.get_mm_embedding(\"Vinho Tinto\", \"images/screenshot-20240422-23.20.19.png\")\n",
        "text_embedding = r.__getattribute__(\"text_embedding\")\n",
        "image_embeddings = r.__getattribute__(\"image_embedding\")\n",
        "distances = embedding_distance(np.array(text_embedding), np.array(image_embeddings))\n",
        "print(f\"Distance: {distances}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance: 0.16450461565085006\n"
          ]
        }
      ],
      "source": [
        "r = e.get_mm_embedding(\"Criança de 1 ano, sentada em tapete, criança para estar feliz brincando, cachorro de brinquedo, balde, cone colorido, cruz de malta, \", \"images/screenshot-20240423-22.24.07.png\")\n",
        "text_embedding = r.__getattribute__(\"text_embedding\")\n",
        "image_embeddings = r.__getattribute__(\"image_embedding\")\n",
        "distances = embedding_distance(np.array(text_embedding), np.array(image_embeddings))\n",
        "print(f\"Distance: {distances}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Text vs Text Comparison "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance: 0.7984022215800726\n"
          ]
        }
      ],
      "source": [
        "r = e.get_text_embedding(\"Vinho Tinto Seco De Martino Premium Gallardía 2019 - Chile 750ml\")\n",
        "text_embedding1 = r\n",
        "r = e.get_text_embedding(\"Vinho Tinto Seco Echo Reserva Especial 2019 - Chile 750ml\")\n",
        "text_embedding2 = r\n",
        "distances = embedding_distance(\n",
        "    np.array(text_embedding1),np.array(text_embedding2)\n",
        ")\n",
        "print(f\"Distance: {distances}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Image vs Image Comparison "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance: 0.6747244359544193\n"
          ]
        }
      ],
      "source": [
        "r = e.get_image_embedding(\"images/screenshot-20240424-06.01.17.png\")\n",
        "image_embedding1 = r\n",
        "r = e.get_image_embedding(\"images/screenshot-20240424-06.00.46.png\")\n",
        "image_embedding2 = r\n",
        "distances = embedding_distance(\n",
        "    np.array(image_embedding1),np.array(image_embedding2)\n",
        ")\n",
        "print(f\"Distance: {distances}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Embeddings API\n",
        "[Docs](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/multimodal-embeddings#sample-request)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!curl -X POST \\\n",
        "     -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "     -H \"Content-Type: application/json; charset=utf-8\" \\\n",
        "     -d @images/text_payload.json \\\n",
        "     \"https://{REGION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{REGION}/publishers/google/models/multimodalembedding@001:predict\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sdk_matching_engine_create_multimodal_embeddings.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
